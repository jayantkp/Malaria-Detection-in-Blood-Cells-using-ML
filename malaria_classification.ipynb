{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importiing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"./cell_images/cell_images\"\n",
    "#uninfected = \"./cell_images/Uninfected\"\n",
    "#parasitized = \"./cell_images/parasitized\"\n",
    "classes = os.listdir(img_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the training and validation dataset from the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "batch_size = 48\n",
    "training_data = keras.preprocessing.image_dataset_from_directory(img_dir,\n",
    "                                                                seed = 45,\n",
    "                                                                validation_split = 0.2,\n",
    "                                                                subset = \"training\",\n",
    "                                                                image_size = (size,size),\n",
    "                                                                batch_size = batch_size)\n",
    "\n",
    "validation_data = keras.preprocessing.image_dataset_from_directory(img_dir,\n",
    "                                                                seed = 45,\n",
    "                                                                validation_split = 0.2,\n",
    "                                                                subset = \"validation\",\n",
    "                                                                image_size = (size,size),\n",
    "                                                                batch_size = batch_size)\n",
    "\n",
    "\n",
    "test_data = keras.preprocessing.image_dataset_from_directory(img_dir,\n",
    "                                                                seed = 45,\n",
    "                                                                validation_split = 0.2,\n",
    "                                                                subset = \"validation\",\n",
    "                                                                image_size = (size,size),\n",
    "                                                                batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.figure(figsize = (12,8))\n",
    "def view_images(target_dir, target_class):\n",
    "    target_folder = target_dir + target_class\n",
    "    \n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    \n",
    "    img = mpimg.imread(target_folder + '/' + random_image[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    \n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    return img\n",
    "uninfected_images = view_images('./cell_images/cell_images/', 'Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parasitized_images = view_images('./cell_images/cell_images/', 'Parasitized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Conv2D, Dropout, BatchNormalization, MaxPool2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape = (64,64,3))\n",
    "data_aug = keras.layers.experimental.preprocessing.Rescaling(1./255)(input)\n",
    "conv1 = Conv2D(32, kernel_size = 3, activation = \"relu\")(data_aug)\n",
    "pool1 = MaxPool2D(2)(conv1)\n",
    "norm1 = BatchNormalization(axis = -1)(pool1)\n",
    "drop1 = Dropout(0.2)(norm1)\n",
    "\n",
    "conv2 = Conv2D(32, kernel_size = 3, activation = \"relu\")(drop1)\n",
    "pool2 = MaxPool2D(2)(conv2)\n",
    "norm2 = BatchNormalization(axis = -1)(pool2)\n",
    "drop2 = Dropout(0.2)(norm2)\n",
    "\n",
    "flatten = Flatten()(drop2)\n",
    "\n",
    "hidden1 = Dense(512, activation = \"relu\")(flatten)\n",
    "norm3 = BatchNormalization(axis = -1)(hidden1)\n",
    "drop3 = Dropout(0.2)(norm3)\n",
    "\n",
    "hidden2 = Dense(512, activation = \"relu\")(drop3)\n",
    "norm4 = BatchNormalization(axis = -1)(hidden2)\n",
    "drop4 = Dropout(0.2)(norm4)\n",
    "\n",
    "output = Dense(2, activation = \"sigmoid\")(drop4)\n",
    "\n",
    "model = keras.Model(inputs = input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"Adam\",\n",
    "             loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(training_data, epochs = 10, validation_data = validation_data, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "    # plot loss\n",
    "    plt.plot(epochs, loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('./cell_images/Parasitized/1.png',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = x/255\n",
    "x=np.expand_dims(x,axis=0)\n",
    "#img_data=preprocess_input(x)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a==1):\n",
    "    print(\"Uninfected\")\n",
    "else:\n",
    "    print(\"Parasitized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
